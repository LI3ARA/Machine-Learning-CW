{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #create data frames(CSV should be converted to structered form)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.tests import TfidfVectorizer # convert text data into numerical data\n",
    "# from sklearn.linear_model import logisticRegression\n",
    "# from sklearn.metrics import accuracy_score #test data is used to test the model- to find the accuarcy needs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Collection and Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n\n      49   50     51     52     53     54   55    56  57  \n0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "url_names = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\"\n",
    "\n",
    "data = pd.read_csv(url,header=None)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(4601, 58)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4601 non-null   float64\n",
      " 1   1       4601 non-null   float64\n",
      " 2   2       4601 non-null   float64\n",
      " 3   3       4601 non-null   float64\n",
      " 4   4       4601 non-null   float64\n",
      " 5   5       4601 non-null   float64\n",
      " 6   6       4601 non-null   float64\n",
      " 7   7       4601 non-null   float64\n",
      " 8   8       4601 non-null   float64\n",
      " 9   9       4601 non-null   float64\n",
      " 10  10      4601 non-null   float64\n",
      " 11  11      4601 non-null   float64\n",
      " 12  12      4601 non-null   float64\n",
      " 13  13      4601 non-null   float64\n",
      " 14  14      4601 non-null   float64\n",
      " 15  15      4601 non-null   float64\n",
      " 16  16      4601 non-null   float64\n",
      " 17  17      4601 non-null   float64\n",
      " 18  18      4601 non-null   float64\n",
      " 19  19      4601 non-null   float64\n",
      " 20  20      4601 non-null   float64\n",
      " 21  21      4601 non-null   float64\n",
      " 22  22      4601 non-null   float64\n",
      " 23  23      4601 non-null   float64\n",
      " 24  24      4601 non-null   float64\n",
      " 25  25      4601 non-null   float64\n",
      " 26  26      4601 non-null   float64\n",
      " 27  27      4601 non-null   float64\n",
      " 28  28      4601 non-null   float64\n",
      " 29  29      4601 non-null   float64\n",
      " 30  30      4601 non-null   float64\n",
      " 31  31      4601 non-null   float64\n",
      " 32  32      4601 non-null   float64\n",
      " 33  33      4601 non-null   float64\n",
      " 34  34      4601 non-null   float64\n",
      " 35  35      4601 non-null   float64\n",
      " 36  36      4601 non-null   float64\n",
      " 37  37      4601 non-null   float64\n",
      " 38  38      4601 non-null   float64\n",
      " 39  39      4601 non-null   float64\n",
      " 40  40      4601 non-null   float64\n",
      " 41  41      4601 non-null   float64\n",
      " 42  42      4601 non-null   float64\n",
      " 43  43      4601 non-null   float64\n",
      " 44  44      4601 non-null   float64\n",
      " 45  45      4601 non-null   float64\n",
      " 46  46      4601 non-null   float64\n",
      " 47  47      4601 non-null   float64\n",
      " 48  48      4601 non-null   float64\n",
      " 49  49      4601 non-null   float64\n",
      " 50  50      4601 non-null   float64\n",
      " 51  51      4601 non-null   float64\n",
      " 52  52      4601 non-null   float64\n",
      " 53  53      4601 non-null   float64\n",
      " 54  54      4601 non-null   float64\n",
      " 55  55      4601 non-null   int64  \n",
      " 56  56      4601 non-null   int64  \n",
      " 57  57      4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#divide into x and y data\n",
    "x = data.iloc[:,0:-1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Splitting the data set  into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=None, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Feature scaling - a method used to normalize the range of independent variables or features of data.\n",
    "# It normalizes data within a certain range\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ssc = StandardScaler()\n",
    "x_train = ssc.fit_transform(x_train)\n",
    "x_test = ssc.fit_transform(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knclassifier = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2) # p- power parameter # metric-metrics used for distance computation\n",
    "# minkowski- euclidean distance\n",
    "\n",
    "knclassifier.fit(x_train,y_train) #fitting classifier to the training set\n",
    "y_knn_predic = knclassifier.predict(x_test) # predicting the test set results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0]\n",
      "[0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_knn_predic[0:5])\n",
    "print (y_test[0:5])\n",
    "# to visually compare the prediction to the actual values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclassifier = DecisionTreeClassifier(random_state=0)\n",
    "dtclassifier.fit(x_train,y_train) #fitting the classifier to the training data set\n",
    "y_dtc_predic = dtclassifier.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0]\n",
      "[0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_dtc_predic[0:5])\n",
    "print (y_test[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the accuracy of the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy:  0.9035621198957429\n",
      "Decision Tree Accuracy:  0.8844483058210252\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"KNN Accuracy: \", metrics.accuracy_score(y_test,y_knn_predic))\n",
    "print(\"Decision Tree Accuracy: \", metrics.accuracy_score(y_test,y_dtc_predic))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from six import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "%matplotlib inline#%% md\n",
    "# Importing the dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #create data frames(CSV should be converted to structered form)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.tests import TfidfVectorizer # convert text data into numerical data\n",
    "# from sklearn.linear_model import logisticRegression\n",
    "# from sklearn.metrics import accuracy_score #test data is used to test the model- to find the accuarcy needs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Collection and Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "url_names = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\"\n",
    "\n",
    "data = pd.read_csv(url,header=None)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#divide into x and y data\n",
    "x = data.iloc[:,0:-1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the data set  into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=None, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature scaling - a method used to normalize the range of independent variables or features of data.\n",
    "# It normalizes data within a certain range\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ssc = StandardScaler()\n",
    "x_train = ssc.fit_transform(x_train)\n",
    "x_test = ssc.fit_transform(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knclassifier = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2) # p- power parameter # metric-metrics used for distance computation\n",
    "# minkowski- euclidean distance\n",
    "\n",
    "knclassifier.fit(x_train,y_train) #fitting classifier to the training set\n",
    "y_knn_predic = knclassifier.predict(x_test) # predicting the test set results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (y_knn_predic[0:5])\n",
    "print (y_test[0:5])\n",
    "# to visually compare the prediction to the actual values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtclassifier = DecisionTreeClassifier(random_state=0)\n",
    "dtclassifier.fit(x_train,y_train) #fitting the classifier to the training data set\n",
    "y_dtc_predic = dtclassifier.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (y_dtc_predic[0:5])\n",
    "print (y_test[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the accuracy of the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"KNN Accuracy: \", metrics.accuracy_score(y_test,y_knn_predic))\n",
    "print(\"Decision Tree Accuracy: \", metrics.accuracy_score(y_test,y_dtc_predic))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_30116\\2490805239.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msix\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mStringIO\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpydotplus\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmpimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'matplotlib'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'inline'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from six import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "filename = \"spamtree.png\"\n",
    "\n",
    "featureNames = data.columns[0:57]\n",
    "# targetNames = data[\"Drug\"].unique().tolist()\n",
    "\n",
    "out=tree.export_graphviz(dtclassifier,feature_names=featureNames,\n",
    "                         out_file=dot_data,\n",
    "                         class_names= [\"ham\", \"spam\"],\n",
    "                         filled=True,\n",
    "                         special_characters=True,\n",
    "                         rotate=False)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png(filename)\n",
    "img = mpimg.imread(filename)\n",
    "\n",
    "plt.figure(figsize=(100, 200))\n",
    "plt.imshow(img,interpolation='nearest')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt # Visualize the training data set results\n",
    "from matplotlib.colors import ListedColormap # used to create a custom color map for the plot\n",
    "\n",
    "x_set, y_set= x_train, y_train #assign values which are used to create a grid of points for the plot\n",
    "x1,x2= np.meshgrid(np.arange(start=x_set[:,0].min()-1,stop=x_set[:,0].max()+1, step = 0.01),np.arange(start=x_set[:,1].min()-1,stop=x_set[:,1].max()+1, step = 0.01))\n",
    "plt.contourf(x1, x2, knclassifier.predict(np.array([x1.ravel(),x2.ravel()]).T).reshape(x1.shape),alpha=0.75, cmap = ListedColormap(('pink','green')))\n",
    "plt.xlim(x1.min(),x1.max())\n",
    "plt.ylim(x1.min(),x1.max())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but KNeighborsClassifier is expecting 57 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [15], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m x_set, y_set\u001B[38;5;241m=\u001B[39m x_train, y_train \u001B[38;5;66;03m#assign values which are used to create a grid of points for the plot\u001B[39;00m\n\u001B[0;32m      9\u001B[0m x1,x2\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmeshgrid(np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39mx_set[:,\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,stop\u001B[38;5;241m=\u001B[39mx_set[:,\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m),np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39mx_set[:,\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,stop\u001B[38;5;241m=\u001B[39mx_set[:,\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m))\n\u001B[1;32m---> 10\u001B[0m plt\u001B[38;5;241m.\u001B[39mcontourf(x1, x2, \u001B[43mknclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(x1\u001B[38;5;241m.\u001B[39mshape),alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.75\u001B[39m, cmap \u001B[38;5;241m=\u001B[39m ListedColormap((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpink\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgreen\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n\u001B[0;32m     11\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlim(x1\u001B[38;5;241m.\u001B[39mmin(),x1\u001B[38;5;241m.\u001B[39mmax())\n\u001B[0;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mylim(x1\u001B[38;5;241m.\u001B[39mmin(),x1\u001B[38;5;241m.\u001B[39mmax())\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:214\u001B[0m, in \u001B[0;36mKNeighborsClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \n\u001B[0;32m    203\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m        Class labels for each data sample.\u001B[39;00m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 214\u001B[0m     neigh_dist, neigh_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m     classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\n\u001B[0;32m    216\u001B[0m     _y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:717\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[1;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[0;32m    715\u001B[0m         X \u001B[38;5;241m=\u001B[39m _check_precomputed(X)\n\u001B[0;32m    716\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 717\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    719\u001B[0m     query_is_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    582\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 585\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 400\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    401\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    402\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    403\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 2 features, but KNeighborsClassifier is expecting 57 features as input."
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Visualize the training data set results\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "# used to create a custom color map for the plot\n",
    "\n",
    "x_set, y_set= x_train, y_train #assign values which are used to create a grid of points for the plot\n",
    "\n",
    "x1,x2= np.meshgrid(np.arange(start=x_set[:,0].min()-1,stop=x_set[:,0].max()+1, step = 0.01),np.arange(start=x_set[:,1].min()-1,stop=x_set[:,1].max()+1, step = 0.01))\n",
    "plt.contourf(x1, x2, knclassifier.predict(np.array([x1.ravel(),x2.ravel()]).T).reshape(x1.shape),alpha=0.75, cmap = ListedColormap(('pink','green')))\n",
    "plt.xlim(x1.min(),x1.max())\n",
    "plt.ylim(x1.min(),x1.max())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
